{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CS109a, Fall 2017\n",
    "Utility functions for the final project.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def standardize(x_1, x_2, cont_cols):\n",
    "    \"\"\"\n",
    "    Use this function to standardize our dataset(s).\n",
    "    @param x_1: The DataFrame to be used for standardizing.\n",
    "                Typically this will be the training dataset\n",
    "    @param x_2: The DataFrame to standardize using the metrics\n",
    "                calculated off of X_1. This will be either the\n",
    "                the test dataset or the training dataset.\n",
    "    @param cont_cols: A list of the continuous columns (i.e the\n",
    "                      columns that we want to standardize.)\n",
    "    \"\"\"\n",
    "\n",
    "    # Continuous data that needs to be standardized\n",
    "    df_cont = x_1[cont_cols]\n",
    "\n",
    "    # Save the mean/std so we can use these values to normalize\n",
    "    # the test data below.\n",
    "    df_mean = df_cont.mean()\n",
    "    df_std = df_cont.std()\n",
    "\n",
    "    x_2[cont_cols] = (x_2[cont_cols] - df_mean) / df_std\n",
    "\n",
    "    return x_2\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"\n",
    "    Use this function to get the data needed for the project.\n",
    "    :return: Project data set\n",
    "    \"\"\"\n",
    "    # The columns we want to consider\n",
    "    cols = [\n",
    "        # Roster ID\n",
    "        'RID',\n",
    "\n",
    "        # Visit Code\n",
    "        'VISCODE',\n",
    "\n",
    "        # Gender\n",
    "        'PTGENDER',\n",
    "\n",
    "        # APOE 4 Gene\n",
    "        'APOE4',\n",
    "\n",
    "        # Race\n",
    "        'PTRACCAT',\n",
    "\n",
    "        # Age at Baseline\n",
    "        'AGE',\n",
    "\n",
    "        # Brain Scan Stuff\n",
    "        'Hippocampus_bl',\n",
    "        'Ventricles_bl',\n",
    "        'WholeBrain_bl',\n",
    "        'Entorhinal_bl',\n",
    "        'Fusiform_bl',\n",
    "        'MidTemp_bl',\n",
    "        'ICV_bl',\n",
    "\n",
    "        # Diagnosis\n",
    "        'DX',\n",
    "        \n",
    "        # Month since baseline\n",
    "        'Month'\n",
    "    ]\n",
    "\n",
    "    categorical_cols = ['PTGENDER','APOE4','PTRACCAT']\n",
    "\n",
    "\n",
    "    # Read the ADNIMerge file\n",
    "    df_am = pd.read_csv('data/ADNIMerge.csv')\n",
    "    df_am = df_am[cols]\n",
    "\n",
    "    # Merge in the response variable\n",
    "    df_y = get_response()\n",
    "    df_am = df_am.merge(df_y, on=\"RID\")\n",
    "    \n",
    "    # Drop the DX column \"y\" is the response col now\n",
    "    df_am = df_am.drop(\"DX\", axis=1)\n",
    "    \n",
    "    # Also drop the Month\n",
    "    df_am = df_am.drop(\"Month\", axis=1)\n",
    "\n",
    "    # Drop RID\n",
    "    # TODO: This is commented out until the final dx is merged in\n",
    "    # df_bl = df_bl.drop('RID', axis=1)\n",
    "\n",
    "    # Drop records with NaN\n",
    "    df_am = df_am.dropna()\n",
    "\n",
    "    # From our EDA we know that we need to log transform the\n",
    "    # Ventricles measurement.\n",
    "    df_am['Ventricles_bl'] = df_am['Ventricles_bl'].apply(np.log)\n",
    "\n",
    "    # One-Hot Encode data\n",
    "    df_am = pd.get_dummies(df_am,\n",
    "                           prefix=categorical_cols,\n",
    "                           columns=categorical_cols,\n",
    "                           drop_first=True)\n",
    "\n",
    "    return df_am\n",
    "\n",
    "\n",
    "def get_response():\n",
    "    \"\"\"\n",
    "    return dataframe with cols: [RID, response]\n",
    "    response is mapped to:\n",
    "    # 0 = CN\n",
    "    # 1 = MCI\n",
    "    # 2 = Dementia\n",
    "    At the time of their last visit determined by max(months)\n",
    "    \"\"\"\n",
    "    df_am = pd.read_csv(\"./data/ADNIMERGE.csv\")\n",
    "    # there are some rows with no \"DX\" let's drop those\n",
    "    df_am = df_am[df_am.DX.notnull()]\n",
    "    # let's assign them each a number\n",
    "    df_response = pd.DataFrame([[0, \"CN\"], [1, \"MCI\"], [2, \"Dementia\"]], columns=[\"y\", \"DX\"])\n",
    "    df_am = df_am.merge(df_response, on=\"DX\")\n",
    "    # only need a few columns for now\n",
    "    df_am = df_am[[\"RID\", \"Month\", \"y\"]]\n",
    "    # group by patient\n",
    "    by_patient = df_am.groupby(\"RID\")\n",
    "    \n",
    "    value_at_max_month = []\n",
    "    for k, v in by_patient:\n",
    "        max_mo = v[\"Month\"].max()\n",
    "        y_at_max_mo = v[v[\"Month\"] == max_mo].y.values[0]\n",
    "        value_at_max_month.append([k, y_at_max_mo])\n",
    "\n",
    "    df_mm = pd.DataFrame(value_at_max_month, columns=[\"RID\", \"y\"])\n",
    "    \n",
    "    return df_mm\n",
    "\n",
    "def test_train_split():\n",
    "    data = get_data()\n",
    "\n",
    "    label = 'y'\n",
    "\n",
    "    continuous_cols = ['AGE',\n",
    "                       'Hippocampus_bl',\n",
    "                       'Ventricles_bl',\n",
    "                       'WholeBrain_bl',\n",
    "                       'Entorhinal_bl',\n",
    "                       'Fusiform_bl',\n",
    "                       'MidTemp_bl',\n",
    "                       'ICV_bl']\n",
    "\n",
    "    # We don't need RID or VISCODE anymore\n",
    "    data_clean = data.drop(['RID', 'VISCODE'], axis=1)\n",
    "\n",
    "    # Prior to splitting, do a quick randomizing shuffle\n",
    "    data_clean = data_clean.sample(frac=1, random_state=17).reset_index(drop=True)\n",
    "\n",
    "    # Index for test/train split.\n",
    "    idx = int(data_clean.shape[0]*.8)\n",
    "\n",
    "    # Split the data into training and test data sets.\n",
    "    data_train = data_clean.iloc[:idx]\n",
    "    data_test = data_clean.iloc[idx:]\n",
    "\n",
    "    # Create our test/training DataFrames\n",
    "    X_train = data_train.drop(label, axis=1)\n",
    "    y_train = data_train[[label]].values.ravel()\n",
    "\n",
    "    X_test = data_test.drop(label, axis=1)\n",
    "    y_test = data_test[[label]].values.ravel()\n",
    "\n",
    "    # Standardize the data\n",
    "    X_test = standardize(X_train, X_test, continuous_cols)\n",
    "    X_train = standardize(X_train, X_train, continuous_cols)\n",
    "\n",
    "return X_train, y_train, X_test, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
